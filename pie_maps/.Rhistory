#######################################################################################################################
total.use <- which(total.exclude==FALSE)
downloads.clean2 <- lapply(total.use,function(x) downloads.clean1[[x]])
#######################################################################################################################
# load taxon translation table
#######################################################################################################################
source(paste(help.fun.loc,'taxa_translation_only_abies.R',sep=''))
pol_table <- readr::read_csv(paste(data.loc,'taxon_names_translated_other_hardwood.csv',sep=''))
#perhaps need to comment this
#######################################################################################################################
setwd('~/workflow_stepps_prediction/')
pollen.output.loc <- 'pollen_data/'
site.names <- matrix(length(downloads.clean2))
1:length(downloads.clean2)
counts <- downloads.clean2[[x]]$counts
colnames(counts) <- gsub(' ','.',colnames(counts))
colnames(counts) <- gsub('/','.',colnames(counts))
counts
x <- 1
counts <- downloads.clean2[[x]]$counts
colnames(counts) <- gsub(' ','.',colnames(counts))
colnames(counts) <- gsub('/','.',colnames(counts))
id <- 1:nrow(counts)
id
counts_id <- as.data.frame(cbind(id,counts))
colnames(counts_id)[1] <-'ID'
counts_trans <- translate_taxa(counts_id,
pol_table,
id_cols = colnames(counts_id)[1])
library(stepps)
counts_trans <- translate_taxa(counts_id,
pol_table,
id_cols = colnames(counts_id)[1])
sample.depth <- downloads.clean2[[x]]$sample.meta$depth
dataset.id <- downloads.clean2[[x]]$dataset$dataset.meta$dataset.id
site.name <- downloads.clean2[[x]]$dataset$site.data$site.name
if(length(sample.depth)!=nrow(counts_trans)){
counts_save_int <- matrix(nrow=length(sample.depth),ncol=(ncol(counts_trans)),data=0)
counts_matrix <- matrix(nrow=nrow(counts_trans),unlist(counts_trans))
colnames(counts_matrix) <- colnames(counts_trans)
counts_save_int[rowSums(counts)>0,] <- counts_matrix
colnames(counts_save_int) <- colnames(counts_trans)
counts_save <- data.frame(depths = sample.depth,counts_save_int[,-1])
}else{
counts_save <- data.frame(depths = sample.depth,counts_trans[,-1])
}
#######################################################################################################################
# produce some meta data
#######################################################################################################################
meta.data.sites  <-
sapply(1:length(downloads.clean2),function(z){
daten <- downloads.clean2[[z]]$dataset
data.frame(dataset.id = daten$dataset.meta$dataset.id,
site.name = daten$site.data$site.name,
lat = daten$site.data$lat,
lon = daten$site.data$long)
})
meta.data.sites
counts_save
#########################################################################################################################
# load meta data
#########################################################################################################################
meta.data.sites <- readRDS(paste(pollen.loc,'meta_data_sites.RDS',sep=''))
###########################################################################################################################
# load ages and pollen data
###########################################################################################################################
setwd('~/workflow_stepps_prediction/')
chron.loc <- 'age-depth/Bchron/output/'
pollen.loc <- 'pollen_data/'
chron_prefix <- 'pollen_sample_depth_'
pollen_prefix <-'pollen_counts_'
site.names <- read.table(paste(pollen.loc,'site_names.txt',sep=''))
file.chronology <- list.files(chron.loc)
file.chronology <- file.chronology[grep(chron_prefix,file.chronology)]
lakes.with.chron <- unlist(strsplit(file.chronology,chron_prefix))[seq(2,2*length(file.chronology),2)]
file.pollen <- list.files(pollen.loc)
file.pollen <- file.pollen[grep('pollen_counts',file.pollen)]
pollen.within.domain <- unlist(strsplit(file.pollen,pollen_prefix))[seq(2,2*length(file.pollen),2)]
lakes.available <- intersect(pollen.within.domain,lakes.with.chron)
lakes.available <- lakes.available[-35]
pollen_chronology <-
lapply(lakes.available,function(x){
#for(x in lakes.available){
lake_name <- x#site.names[x,1]
pollen.data <- read.csv(paste(pollen.loc,pollen_prefix,lake_name,sep=''))
chron.data <- read.csv(paste(chron.loc,chron_prefix,lake_name,sep=''))
depths.equal <- all.equal(chron.data$depths-1,pollen.data$depth) # important: these sites have the same depths!!
if(depths.equal != TRUE) {stop('Depths do not match')}
data.frame(age= round(rowMeans(chron.data[,-1],na.rm=TRUE)),pollen.data[,-1])
}
)
names(pollen_chronology) <- lakes.available
saveRDS(pollen_chronology,paste(pollen.loc,'compiled_pollen.RDS',sep=''))
#########################################################################################################################
# load meta data
#########################################################################################################################
meta.data.sites <- readRDS(paste(pollen.loc,'meta_data_sites.RDS',sep=''))
meta.names <- as.character(unlist(meta.data.sites['site.name',]))
meta.data.sites
#########################################################################################################################
# load meta data
#########################################################################################################################
meta.data.sites <- readRDS(paste(pollen.loc,'meta_data_sites.RDS',sep=''))
meta.dataset.id <- as.character(unlist(meta.data.sites['dataset.id',]))
meta.dataset.id
meta.dataset.id <- unlist(meta.data.sites['dataset.id',])
lakes.available
lakes.available2 <- unlist(strsplit(lakes.available,'.csv'))
lakes.available2
lakes.available2 <- unlist(strsplit(lakes.available2,'dataset_id'))
lakes.available2
unlist(strsplit(lakes.available2,'dataset_id_'))[seq(2,2*length(lakes.available),2)]
strsplit(lakes.available2,'dataset_id_')
lakes.available2
lakes.available2 <- unlist(strsplit(lakes.available,'.csv'))
lakes.available2 <- unlist(strsplit(lakes.available2,'dataset_id_'))[seq(2,2*length(lakes.available),2)]
lakes.available2
lakes.available2 <- as.numeric(unlist(strsplit(lakes.available2,'dataset_id_'))[seq(2,2*length(lakes.available),2)])
lakes.available2
lakes.available2 <- unlist(strsplit(lakes.available,'.csv'))
lakes.available2 <- unlist(strsplit(lakes.available2,'dataset_id_'))[seq(2,2*length(lakes.available),2)]
lakes.available2
as.numeric(lakes.available2)
lakes.available2 <- as.numeric(lakes.available2)
lakes.available2
sum(meta.dataset.id%in%lakes.available2)
meta.dataset.id%in%lakes.available2
meta.data.sites[,meta.dataset.id%in%lakes.available2]
meta.data.sites <- meta.data.sites[,meta.dataset.id%in%lakes.available2]
saveRDS(meta.data.sites,paste(pollen.loc,'meta_data_sites.RDS',sep=''))
###################################################################################################################3
# Aggregate pollen to a certain age
###################################################################################################################
setwd('~/workflow_stepps_prediction/')
chron.loc <- 'age-depth/Bchron/output/'
pollen.loc <- 'pollen_data/'
pollen_chronology <- readRDS(paste(pollen.loc,'compiled_pollen.RDS',sep=''))
taxa <- c('Ash','Beech','Birch','Chestnut','Hemlock','Hickory','Maple','Oak','Other.conifer','Other.hardwood','Pine',
'Spruce','Tamarack')
K <- length(taxa)
fake.counts <- data.frame(t(rep(0,K+1)))
names(fake.counts) <- c('age',taxa)
aggregated.pollen <-
lapply(1:length(pollen_chronology),function(z){
#for(z in 1:length(pollen_chronology)){
ages.agg <- seq(150,1950,100)
ages <- pollen_chronology[[z]]$age
ages.2k.index <- ((ages>50)&(ages<2050))
ages.2k <- ages[ages.2k.index]
if(length(ages.2k)>0){
ages.assign <- sapply(ages.2k, function(x) ages.agg[which.min(abs(ages.agg - x))])
pollen.aggregated <- aggregate(pollen_chronology[[z]][ages.2k.index,-1],list(age=ages.assign),FUN=sum)
pollen.aggregated <- matrix(ncol=14,unlist(analogue::join(fake.counts,pollen.aggregated)$pollen))
#pollen.aggregated <- as.data.frame(pollen.aggregated)
colnames(pollen.aggregated) <- colnames(fake.counts)
pollen.final <- matrix(ncol = 14, nrow=length(ages.agg),data=0)
pollen.final[,1] <- ages.agg
pollen.final[ages.agg%in%pollen.aggregated[,'age'],] <- pollen.aggregated
colnames(pollen.final) <- colnames(pollen.aggregated)
pollen.final
}
})
names(aggregated.pollen) <- names(pollen_chronology)
saveRDS(aggregated.pollen,paste(pollen.loc,'aggregated_pollen.RDS',sep=''))
########################################################################################################################
# merge all datasets
########################################################################################################################
pollen.def <- aggregated.pollen[[1]]
for (i in 2:length(aggregated.pollen)){
pollen.def <- rbind(pollen.def,aggregated.pollen[[i]])
}
pollen.def <- pollen.def[,colnames(pollen.def)!='age']
saveRDS(pollen.def,paste(pollen.loc,'pollen_def.RDS',sep=''))
########################################################################################################################
#coordinates of sites used!!
########################################################################################################################
meta.data.sites <- readRDS(paste(pollen.loc,"meta_data_sites.RDS",sep=''))
dataset.ids <- unlist(meta.data.sites['dataset.id',])
index.use <- sapply(1:length(dataset.ids),function(x) length(grep(as.character(dataset.ids[x]),names(aggregated.pollen)))>0)
site.meta <- meta.data.sites[,index.use]
coordinates.sites <- t(site.meta[c('lon','lat'),])
#there are a few sites without data remove theses sites.
#find datasets without data :)
index.no.data <- sapply(aggregated.pollen,function(x) !is.null(x))
coordinates.sites <- coordinates.sites[index.no.data,]
saveRDS(coordinates.sites,paste(pollen.loc,'coordinates_def.RDS',sep=''))
rm(list=ls(all=TRUE))
#########################################################################################################################
# make pie plots of fossil data
#########################################################################################################################
library(sp)
library(maptools)
setwd('~/workflow_stepps_prediction/pie_maps/')
data.loc <- '~/workflow_stepps_prediction/pollen_data/'
plot.loc <- 'plots/'
source('utils/dataPlotFuns.r')
source('utils/simDataFuns.r')
#################################################################################################################
#load vegetation coordinates
#################################################################################################################
load('~/workflow_stepps_calibration/calibration/data/elicitation_neus_certainty_median_80_sites_only_abies_new_species.RData')
rm(y)
centers   = veg_coords#centers_veg
colnames(centers) = c('x', 'y')
xlo = min(centers[,1])
xhi = max(centers[,1])
ylo = min(centers[,2])
yhi = max(centers[,2])
shift=30000
#load pollen data
pollen.def <- readRDS(paste(data.loc,'pollen_def.RDS',sep=''))
pollen_coordinates <- readRDS(paste(data.loc,'coordinates_def.RDS',sep=''))
pollen_coordinates <- matrix(as.numeric(pollen_coordinates),ncol=2)
sputm <- SpatialPoints(pollen_coordinates, proj4string=CRS("+init=epsg:4326"))
spgeo <- spTransform(sputm, CRS("+init=epsg:3175"))
pollen_coord_us <- spgeo@coords
new.order = order(colSums(pollen.def), decreasing=TRUE)
taxa <- colnames(pollen.def)
taxa = taxa[new.order]
pollen.def = pollen.def[,new.order]
col_list = c("#1F78B4", "#33A02C", "#E31A1C", "#6A3D9A", "#B15928", "#FF7F00",
"#FFFF99", "#A6CEE3", "#B2DF8A", "#FB9A99", "#FDBF6F",'cyan',"#CAB2D6")
pdf(paste(plot.loc,'pie_maps_downcore.pdf',sep=''),height =15, width = 15)
sapply(1:19, function(x){
pollen.use <- pollen.def[seq(x,nrow(pollen.def),19),]
pollen = pollen.use
pollen_props  = t(apply(pollen, 1, function(x) x/sum(x)))
colnames(pollen_props) = taxa
centers <- pollen_coord_us
colnames(centers) = c('x', 'y')
centers <- centers[is.finite(rowSums(pollen_props)),]
pollen_props <- pollen_props[is.finite(rowSums(pollen_props)),]
par(mfrow=c(1,1))
pieMap(proportions = pollen_props,
centers  = centers,
restrict = FALSE,
inputRestricted = FALSE,
xlim   = c(xlo+shift, xhi-shift),
ylim   = c(ylo+shift, yhi-shift),
radius = 18000,
scale  = 1,
xlab   = 'x',
ylab   = 'y',
add_legend=TRUE,
main_title='',
col_list=col_list)
})
dev.off()
coordinates.sites
########################################################################################################################
#coordinates of sites used!!
########################################################################################################################
meta.data.sites <- readRDS(paste(pollen.loc,"meta_data_sites.RDS",sep=''))
###################################################################################################################3
# Aggregate pollen to a certain age
###################################################################################################################
setwd('~/workflow_stepps_prediction/')
chron.loc <- 'age-depth/Bchron/output/'
pollen.loc <- 'pollen_data/'
pollen_chronology <- readRDS(paste(pollen.loc,'compiled_pollen.RDS',sep=''))
taxa <- c('Ash','Beech','Birch','Chestnut','Hemlock','Hickory','Maple','Oak','Other.conifer','Other.hardwood','Pine',
'Spruce','Tamarack')
K <- length(taxa)
fake.counts <- data.frame(t(rep(0,K+1)))
names(fake.counts) <- c('age',taxa)
aggregated.pollen <-
lapply(1:length(pollen_chronology),function(z){
#for(z in 1:length(pollen_chronology)){
ages.agg <- seq(150,1950,100)
ages <- pollen_chronology[[z]]$age
ages.2k.index <- ((ages>50)&(ages<2050))
ages.2k <- ages[ages.2k.index]
if(length(ages.2k)>0){
ages.assign <- sapply(ages.2k, function(x) ages.agg[which.min(abs(ages.agg - x))])
pollen.aggregated <- aggregate(pollen_chronology[[z]][ages.2k.index,-1],list(age=ages.assign),FUN=sum)
pollen.aggregated <- matrix(ncol=14,unlist(analogue::join(fake.counts,pollen.aggregated)$pollen))
#pollen.aggregated <- as.data.frame(pollen.aggregated)
colnames(pollen.aggregated) <- colnames(fake.counts)
pollen.final <- matrix(ncol = 14, nrow=length(ages.agg),data=0)
pollen.final[,1] <- ages.agg
pollen.final[ages.agg%in%pollen.aggregated[,'age'],] <- pollen.aggregated
colnames(pollen.final) <- colnames(pollen.aggregated)
pollen.final
}
})
names(aggregated.pollen) <- names(pollen_chronology)
saveRDS(aggregated.pollen,paste(pollen.loc,'aggregated_pollen.RDS',sep=''))
########################################################################################################################
# merge all datasets
########################################################################################################################
pollen.def <- aggregated.pollen[[1]]
for (i in 2:length(aggregated.pollen)){
pollen.def <- rbind(pollen.def,aggregated.pollen[[i]])
}
pollen.def <- pollen.def[,colnames(pollen.def)!='age']
saveRDS(pollen.def,paste(pollen.loc,'pollen_def.RDS',sep=''))
########################################################################################################################
#coordinates of sites used!!
########################################################################################################################
meta.data.sites <- readRDS(paste(pollen.loc,"meta_data_sites.RDS",sep=''))
dataset.ids <- unlist(meta.data.sites['dataset.id',])
index.use <- sapply(1:length(dataset.ids),function(x) length(grep(as.character(dataset.ids[x]),names(aggregated.pollen)))>0)
site.meta <- meta.data.sites[,index.use]
coordinates.sites <- t(site.meta[c('lon','lat'),])
#there are a few sites without data remove theses sites.
#find datasets without data :)
index.no.data <- sapply(aggregated.pollen,function(x) !is.null(x))
coordinates.sites <- coordinates.sites[index.no.data,]
saveRDS(coordinates.sites,paste(pollen.loc,'coordinates_def.RDS',sep=''))
meta.data.sites
index.use
site.meta <- meta.data.sites[,index.use]
coordinates.sites <- t(site.meta[c('lon','lat'),])
coordinates.sites
index.no.data
coordinates.sites <- coordinates.sites[index.no.data,]
coordinates.sites
seq(150,1950,100)
length(seq(150,1950,100))
pollen_chronology <- readRDS(paste(pollen.loc,'compiled_pollen.RDS',sep=''))
pollen_chronology
meta.data.sites
lakes.available2
meta.data.sites <- readRDS(paste(pollen.loc,'meta_data_sites.RDS',sep=''))
meta.dataset.id <- unlist(meta.data.sites['dataset.id',])
lakes.available2 <- unlist(strsplit(lakes.available,'.csv'))
lakes.available2 <- unlist(strsplit(lakes.available2,'dataset_id_'))[seq(2,2*length(lakes.available),2)]
lakes.available2 <- as.numeric(lakes.available2)
###########################################################################################################################
# load ages and pollen data
###########################################################################################################################
setwd('~/workflow_stepps_prediction/')
chron.loc <- 'age-depth/Bchron/output/'
pollen.loc <- 'pollen_data/'
chron_prefix <- 'pollen_sample_depth_'
pollen_prefix <-'pollen_counts_'
site.names <- read.table(paste(pollen.loc,'site_names.txt',sep=''))
file.chronology <- list.files(chron.loc)
file.chronology <- file.chronology[grep(chron_prefix,file.chronology)]
lakes.with.chron <- unlist(strsplit(file.chronology,chron_prefix))[seq(2,2*length(file.chronology),2)]
file.pollen <- list.files(pollen.loc)
file.pollen <- file.pollen[grep('pollen_counts',file.pollen)]
pollen.within.domain <- unlist(strsplit(file.pollen,pollen_prefix))[seq(2,2*length(file.pollen),2)]
lakes.available <- intersect(pollen.within.domain,lakes.with.chron)
lakes.available <- lakes.available[-35]
pollen_chronology <-
lapply(lakes.available,function(x){
#for(x in lakes.available){
lake_name <- x#site.names[x,1]
pollen.data <- read.csv(paste(pollen.loc,pollen_prefix,lake_name,sep=''))
chron.data <- read.csv(paste(chron.loc,chron_prefix,lake_name,sep=''))
depths.equal <- all.equal(chron.data$depths-1,pollen.data$depth) # important: these sites have the same depths!!
if(depths.equal != TRUE) {stop('Depths do not match')}
data.frame(age= round(rowMeans(chron.data[,-1],na.rm=TRUE)),pollen.data[,-1])
}
)
names(pollen_chronology) <- lakes.available
saveRDS(pollen_chronology,paste(pollen.loc,'compiled_pollen.RDS',sep=''))
#########################################################################################################################
# load meta data
#########################################################################################################################
meta.data.sites <- readRDS(paste(pollen.loc,'meta_data_sites.RDS',sep=''))
meta.dataset.id <- unlist(meta.data.sites['dataset.id',])
lakes.available2 <- unlist(strsplit(lakes.available,'.csv'))
lakes.available2 <- unlist(strsplit(lakes.available2,'dataset_id_'))[seq(2,2*length(lakes.available),2)]
lakes.available2 <- as.numeric(lakes.available2)
sum(meta.dataset.id%in%lakes.available2)
meta.data.sites <- meta.data.sites[,meta.dataset.id%in%lakes.available2]
saveRDS(meta.data.sites,paste(pollen.loc,'meta_data_sites.RDS',sep=''))
lakes.available2
order(lakes.available2)
meta.data.sites[,order(lakes.available2)]
order(lakes.available2)
lakes.available2[order(lakes.available2)]
aveRDS(lakes.available2,paste(pollen.loc,'order_dataset_ids.RDS'))
saveRDS(lakes.available2,paste(pollen.loc,'order_dataset_ids.RDS'))
# we have to reorder the data
ordering_dataset_ids <- readRDS(paste(pollen.loc,'order_dataset_ids.RDS'))
ordering_dataset_ids
order(ordering_dataset_ids)
aggregated.pollen <-
lapply(order(ordering_dataset_ids),function(z){
#for(z in 1:length(pollen_chronology)){
ages.agg <- seq(150,1950,100)
ages <- pollen_chronology[[z]]$age
ages.2k.index <- ((ages>50)&(ages<2050))
ages.2k <- ages[ages.2k.index]
if(length(ages.2k)>0){
ages.assign <- sapply(ages.2k, function(x) ages.agg[which.min(abs(ages.agg - x))])
pollen.aggregated <- aggregate(pollen_chronology[[z]][ages.2k.index,-1],list(age=ages.assign),FUN=sum)
pollen.aggregated <- matrix(ncol=14,unlist(analogue::join(fake.counts,pollen.aggregated)$pollen))
#pollen.aggregated <- as.data.frame(pollen.aggregated)
colnames(pollen.aggregated) <- colnames(fake.counts)
pollen.final <- matrix(ncol = 14, nrow=length(ages.agg),data=0)
pollen.final[,1] <- ages.agg
pollen.final[ages.agg%in%pollen.aggregated[,'age'],] <- pollen.aggregated
colnames(pollen.final) <- colnames(pollen.aggregated)
pollen.final
}
})
names(aggregated.pollen) <- names(pollen_chronology)
saveRDS(aggregated.pollen,paste(pollen.loc,'aggregated_pollen.RDS',sep=''))
########################################################################################################################
# merge all datasets
########################################################################################################################
pollen.def <- aggregated.pollen[[1]]
for (i in 2:length(aggregated.pollen)){
pollen.def <- rbind(pollen.def,aggregated.pollen[[i]])
}
pollen.def <- pollen.def[,colnames(pollen.def)!='age']
saveRDS(pollen.def,paste(pollen.loc,'pollen_def.RDS',sep=''))
########################################################################################################################
#coordinates of sites used!!
########################################################################################################################
meta.data.sites <- readRDS(paste(pollen.loc,"meta_data_sites.RDS",sep=''))
dataset.ids <- unlist(meta.data.sites['dataset.id',])
index.use <- sapply(1:length(dataset.ids),function(x) length(grep(as.character(dataset.ids[x]),names(aggregated.pollen)))>0)
site.meta <- meta.data.sites[,index.use]
coordinates.sites <- t(site.meta[c('lon','lat'),])
#there are a few sites without data remove theses sites.
#find datasets without data :)
index.no.data <- sapply(aggregated.pollen,function(x) !is.null(x))
coordinates.sites <- coordinates.sites[index.no.data,]
saveRDS(coordinates.sites,paste(pollen.loc,'coordinates_def.RDS',sep=''))
#########################################################################################################################
# make pie plots of fossil data
#########################################################################################################################
library(sp)
library(maptools)
setwd('~/workflow_stepps_prediction/pie_maps/')
data.loc <- '~/workflow_stepps_prediction/pollen_data/'
plot.loc <- 'plots/'
source('utils/dataPlotFuns.r')
source('utils/simDataFuns.r')
#################################################################################################################
#load vegetation coordinates
#################################################################################################################
load('~/workflow_stepps_calibration/calibration/data/elicitation_neus_certainty_median_80_sites_only_abies_new_species.RData')
rm(y)
centers   = veg_coords#centers_veg
colnames(centers) = c('x', 'y')
xlo = min(centers[,1])
xhi = max(centers[,1])
ylo = min(centers[,2])
yhi = max(centers[,2])
shift=30000
#load pollen data
pollen.def <- readRDS(paste(data.loc,'pollen_def.RDS',sep=''))
pollen_coordinates <- readRDS(paste(data.loc,'coordinates_def.RDS',sep=''))
pollen_coordinates <- matrix(as.numeric(pollen_coordinates),ncol=2)
sputm <- SpatialPoints(pollen_coordinates, proj4string=CRS("+init=epsg:4326"))
spgeo <- spTransform(sputm, CRS("+init=epsg:3175"))
pollen_coord_us <- spgeo@coords
new.order = order(colSums(pollen.def), decreasing=TRUE)
taxa <- colnames(pollen.def)
taxa = taxa[new.order]
pollen.def = pollen.def[,new.order]
col_list = c("#1F78B4", "#33A02C", "#E31A1C", "#6A3D9A", "#B15928", "#FF7F00",
"#FFFF99", "#A6CEE3", "#B2DF8A", "#FB9A99", "#FDBF6F",'cyan',"#CAB2D6")
pdf(paste(plot.loc,'pie_maps_downcore.pdf',sep=''),height =15, width = 15)
sapply(1:19, function(x){
pollen.use <- pollen.def[seq(x,nrow(pollen.def),19),]
pollen = pollen.use
pollen_props  = t(apply(pollen, 1, function(x) x/sum(x)))
colnames(pollen_props) = taxa
centers <- pollen_coord_us
colnames(centers) = c('x', 'y')
centers <- centers[is.finite(rowSums(pollen_props)),]
pollen_props <- pollen_props[is.finite(rowSums(pollen_props)),]
par(mfrow=c(1,1))
pieMap(proportions = pollen_props,
centers  = centers,
restrict = FALSE,
inputRestricted = FALSE,
xlim   = c(xlo+shift, xhi-shift),
ylim   = c(ylo+shift, yhi-shift),
radius = 18000,
scale  = 1,
xlab   = 'x',
ylab   = 'y',
add_legend=TRUE,
main_title='',
col_list=col_list)
})
dev.off()
years <- seq(150,1950,100)
pdf(paste(plot.loc,'pie_maps_downcore.pdf',sep=''),height =15, width = 15)
sapply(1:19, function(x){
pollen.use <- pollen.def[seq(x,nrow(pollen.def),19),]
pollen = pollen.use
pollen_props  = t(apply(pollen, 1, function(x) x/sum(x)))
colnames(pollen_props) = taxa
centers <- pollen_coord_us
colnames(centers) = c('x', 'y')
centers <- centers[is.finite(rowSums(pollen_props)),]
pollen_props <- pollen_props[is.finite(rowSums(pollen_props)),]
par(mfrow=c(1,1))
pieMap(proportions = pollen_props,
centers  = centers,
restrict = FALSE,
inputRestricted = FALSE,
xlim   = c(xlo+shift, xhi-shift),
ylim   = c(ylo+shift, yhi-shift),
radius = 18000,
scale  = 1,
xlab   = 'x',
ylab   = 'y',
add_legend=TRUE,
main_title= paste(years[x], 'cal BP') ,
col_list=col_list)
})
dev.off()
